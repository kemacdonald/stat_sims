<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Stats 60: Learning stats via simulation</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This book aims to teach statistical concepts at an introductory level, using a functional and simulation approach.">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Stats 60: Learning stats via simulation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book aims to teach statistical concepts at an introductory level, using a functional and simulation approach." />
  <meta name="github-repo" content="stat_sims" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stats 60: Learning stats via simulation" />
  
  <meta name="twitter:description" content="This book aims to teach statistical concepts at an introductory level, using a functional and simulation approach." />
  

<meta name="author" content="Stats 60 TAs">


<meta name="date" content="2017-01-01">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="descriptives.html">


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stats 60: Learning stats via simulation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>2</b> Simulation</a><ul>
<li class="chapter" data-level="2.1" data-path="simulation.html"><a href="simulation.html#why-simulate-data"><i class="fa fa-check"></i><b>2.1</b> Why simulate data?</a></li>
<li class="chapter" data-level="2.2" data-path="simulation.html"><a href="simulation.html#setting-the-seed"><i class="fa fa-check"></i><b>2.2</b> Setting the seed</a></li>
<li class="chapter" data-level="2.3" data-path="simulation.html"><a href="simulation.html#generating-samples-from-probability-distributions"><i class="fa fa-check"></i><b>2.3</b> Generating samples from probability distributions</a></li>
<li class="chapter" data-level="2.4" data-path="simulation.html"><a href="simulation.html#repetition"><i class="fa fa-check"></i><b>2.4</b> Repetition</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>3</b> Descriptive statistics and data vizualization</a><ul>
<li class="chapter" data-level="3.1" data-path="descriptives.html"><a href="descriptives.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>3.1</b> Measures of central tendency</a><ul>
<li class="chapter" data-level="3.1.1" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>3.1.1</b> Mean</a></li>
<li class="chapter" data-level="3.1.2" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>3.1.2</b> Median</a></li>
<li class="chapter" data-level="3.1.3" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>3.1.3</b> Mode</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="descriptives.html"><a href="descriptives.html#measures-of-variability"><i class="fa fa-check"></i><b>3.2</b> Measures of variability</a><ul>
<li class="chapter" data-level="3.2.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>3.2.1</b> Range</a></li>
<li class="chapter" data-level="3.2.2" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>3.2.2</b> Interquartile range</a></li>
<li class="chapter" data-level="3.2.3" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>3.2.3</b> Variance</a></li>
<li class="chapter" data-level="3.2.4" data-path="descriptives.html"><a href="descriptives.html#standard-deviation"><i class="fa fa-check"></i><b>3.2.4</b> Standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="descriptives.html"><a href="descriptives.html#standard-scores"><i class="fa fa-check"></i><b>3.3</b> Standard scores</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="t-test.html"><a href="t-test.html"><i class="fa fa-check"></i><b>4</b> T-test</a><ul>
<li class="chapter" data-level="4.1" data-path="t-test.html"><a href="t-test.html#the-t-test-what-why-and-how"><i class="fa fa-check"></i><b>4.1</b> The t-test (what, why, and how)</a><ul>
<li class="chapter" data-level="4.1.1" data-path="t-test.html"><a href="t-test.html#how-to-compute-a-t-statistic"><i class="fa fa-check"></i><b>4.1.1</b> How to compute a t-statistic?</a></li>
<li class="chapter" data-level="4.1.2" data-path="t-test.html"><a href="t-test.html#how-do-we-use-a-t-statistic"><i class="fa fa-check"></i><b>4.1.2</b> How do we use a t-statistic?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="t-test.html"><a href="t-test.html#comparing-samples-from-two-different-groups"><i class="fa fa-check"></i><b>4.2</b> Comparing samples from two different groups</a></li>
<li class="chapter" data-level="4.3" data-path="t-test.html"><a href="t-test.html#exploring-the-normality-assumption-of-the-t-test"><i class="fa fa-check"></i><b>4.3</b> Exploring the normality assumption of the t-test</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stats 60: Learning stats via simulation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="t-test" class="section level1">
<h1><span class="header-section-number">Chapter: 4</span> T-test</h1>
<div id="the-t-test-what-why-and-how" class="section level2">
<h2><span class="header-section-number">4.1</span> The t-test (what, why, and how)</h2>
<p>The t-test refers to a widely-used set of statistical tools that help us to determine whether two values are “actually” different from each other. (Note the “actually” part will become more clear when we dive into the topic of p-values.) It was developed by William Gosset as a method of statistical quality control to monitor the quality of stout production (there’s a neat backstory that I recommend reading!).</p>
<div id="how-to-compute-a-t-statistic" class="section level3">
<h3><span class="header-section-number">4.1.1</span> How to compute a t-statistic?</h3>
<p>The algorithm for computing a t-statistic is as follows:</p>
<ul>
<li><p>First, we need to determine the null and the alternative hypothesis. This will depend on the type of comparison you want to make. For example, Let’s imagine that you have taken a series of measures on a single group (e.g., NBA players’ heights). You might be interested in testing whether the average height of an NBA player is different from the average height of the general population in the United States. In this scenario, your null hypothesis, <span class="math inline">\(H_0\)</span>, is that the average heights are not different from each other, and your alternative hypothesis, <span class="math inline">\(H_a\)</span>, is that the two groups are different. (IMPORTANT: here we are just saying that the groups could be different in some way, meaning the NBA players could be shorter OR taller on average.)</p></li>
<li><p>Second, we need to compute the values that will be in the input to the t-test computation. Here is the formula for a one-sample t-test:</p></li>
</ul>
<p><span class="math display">\[t = \frac{\bar{x} - u_0} {s / \sqrt{n}}\]</span></p>
<p>Let’s code up the one-sample t-test as a function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_test_fun &lt;-<span class="st"> </span>function(measurements, null_val) {
  xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(measurements)
  s &lt;-<span class="st"> </span><span class="kw">sd</span>(measurements)
  n &lt;-<span class="st"> </span><span class="kw">length</span>(measurements)
  <span class="co"># compute t-statistic</span>
  (xbar -<span class="st"> </span>null_val) /<span class="st"> </span>(s /<span class="st"> </span><span class="kw">sqrt</span>(n))
  
}</code></pre></div>
<p>Let’s try our t-test function and compare the output ot R’s built-in <code>t.test()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate some data as samples from a normal distribution</span>
samples &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">6</span>, <span class="dt">sd =</span> <span class="fl">1.5</span>)
our_t &lt;-<span class="st"> </span><span class="kw">t_test_fun</span>(<span class="dt">measurements =</span> samples, <span class="dt">null_val =</span> <span class="dv">6</span>)

<span class="co"># R&#39;s built-in t-test function</span>
Rs_t &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> samples, <span class="dt">mu =</span> <span class="dv">6</span>)$statistic</code></pre></div>
<p>Our t-statistic is -0.9956524 and R’s is -0.9956524. Nice! Our function worked and returned the expected t-statistic.</p>
<p>But a t-statistic by itself is not all that useful in helping us to decide whether there is a difference between our measurements and the null value. In the next section, we will show how to use a t-statistic to make decisions (draw inferences) about our data.</p>
</div>
<div id="how-do-we-use-a-t-statistic" class="section level3">
<h3><span class="header-section-number">4.1.2</span> How do we use a t-statistic?</h3>
<p>To understand how we use a t-statistic, we need to understand the t-distribution. As always Wikipedia provides a useful description:</p>
<blockquote>
<p>Student’s t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arises when estimating the mean of a normally distributed population in situations where the sample size is small and population standard deviation is unknown. It was developed by William Sealy Gosset under the pseudonym Student. Whereas a normal distribution describes a full population, t-distributions describe samples drawn from a full population; accordingly, the t-distribution for each sample size is different, and the larger the sample, the more the distribution resembles a normal distribution.</p>
</blockquote>
<p>There’s a lot of information in that description! Let’s unpack it.</p>
<p>The t-distribution is described by three parameters: the mean (location), the standard deviation (spread), and the degrees of freedom (area in the tails).<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> Here’s what the t-distribution looks like for several different values of degrees of freedom.</p>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-18-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>The key parameter for the t-distribution is degrees of freedom (df). Note that a smaller df value creates a distribution with more area in the tails (shorter and wider) than one with a larger df value. Intuitively, this means that you would need a larger t-statistic to achieve the same probability to reject the null hypothesis that the observed mean in our sample is different from the null value.</p>
<p>The key insight about the t-distribution is that it provides the <em>expected</em> distribution of t-statistics if we assumed that the null hypothesis was true (that there is no difference between our sample measurments and the population value). Let’s use our simulation skills to test this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_sims_null &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">1000</span>, 
                    <span class="kw">t.test</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">mu =</span> <span class="dv">0</span>)$statistic) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>()

  <span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .), <span class="dt">data =</span> t_sims_null) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="dt">stat=</span><span class="st">&quot;density&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>) +
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">rt</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">df =</span> <span class="dv">99</span>)), <span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, 
            <span class="dt">color =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-19-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>Now when we compute a t-statistic for our sample, the question we will ask is: how likely is this t-statistic if we assume that the null hypothesis is true. And since we now have an expected probability distribution of t-statistics, we can compare where our t-value falls in this distribution. Intuitively, if it is towards the center of the probability distribution (where there is a lot of probability mass), then it is more likely that our sample t-value was generated from same process that generated the null distribution.</p>
<p>To actually do this in R, we can use the <code>pt()</code> function, which returns the probability of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span>*<span class="kw">pt</span>(-<span class="kw">abs</span>(our_t), <span class="dt">df =</span> <span class="kw">length</span>(samples) -<span class="st"> </span><span class="dv">1</span>) ==<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> samples, <span class="dt">mu =</span> <span class="dv">6</span>)$p.value</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>We can also visualize the location of our t-statistic relative to the null t-distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .), <span class="dt">data =</span> t_sims_null) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> our_t, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-21-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>We can see that the location of our t-statistic is not very far out in the tails of the distribution, meaning that it is unlikely that our measurements were generated by a process that was different from the process that generated the collection of t-statistics in the null distribution (if we assume that there is no difference).</p>
<p>But what would a t-statistic look like if there was a difference between our sample and the population value?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samples2_nba &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">mean =</span> <span class="fl">6.5</span>, <span class="dt">sd =</span> <span class="fl">1.5</span>)
sig_t &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> samples2_nba, <span class="dt">mu =</span> <span class="dv">6</span>)$statistic</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .), <span class="dt">data =</span> t_sims_null) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> our_t, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sig_t, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-23-1.png" width="432" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="comparing-samples-from-two-different-groups" class="section level2">
<h2><span class="header-section-number">4.2</span> Comparing samples from two different groups</h2>
<p><span class="math display">\[t = \frac{\bar{x_1} - \bar{x_2}} {s_p \sqrt{2/n}}\]</span></p>
<p>Where <span class="math inline">\(s_p\)</span> is the pooled standard deviation that we use to etsimate the variance of the two populations that we are sampling from.</p>
<p><span class="math display">\[s_p = \sqrt{\frac{s^2_{x_1} + s^2_{x_2}}{2}}\]</span></p>
<p>Next, let’s write a function that allows us to simulate an experiment where we collect from two different groups and we want to know whether there is likely to be a difference between the two groups. To answer this question, we perform a two-sample, independent t-test on the mean difference between the groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_two_samp_ttest &lt;-<span class="st"> </span>function(n_samps, m1, sd1, m2, sd2, <span class="dt">paired =</span> <span class="ot">FALSE</span>) {
  group1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> n_samps, <span class="dt">m =</span> m1, <span class="dt">sd =</span> sd1)
  group2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> n_samps, <span class="dt">m =</span> m2, <span class="dt">sd =</span> sd2)
  
  <span class="kw">t.test</span>(group1, group2, <span class="dt">paired =</span> paired)$p.value
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">replicate</span>(<span class="dv">1000</span>, 
          <span class="kw">sim_two_samp_ttest</span>(<span class="dt">n_samps =</span> <span class="dv">200</span>, <span class="dt">m1 =</span> <span class="dv">5</span>, <span class="dt">sd1 =</span> <span class="fl">0.5</span>, <span class="dt">m2 =</span> <span class="fl">5.1</span>, <span class="dt">sd2 =</span> <span class="fl">0.5</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>() %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(.)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), <span class="dt">bins =</span> <span class="dv">50</span>) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density.., <span class="dt">color =</span> <span class="st">&quot;Empirical density&quot;</span>), <span class="dt">stat =</span> <span class="st">&#39;density&#39;</span>, 
            <span class="dt">size =</span> <span class="fl">1.5</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> .<span class="dv">05</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>)</code></pre></div>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-25-1.png" width="432" style="display: block; margin: auto;" /></p>
</div>
<div id="exploring-the-normality-assumption-of-the-t-test" class="section level2">
<h2><span class="header-section-number">4.3</span> Exploring the normality assumption of the t-test</h2>
<p>The t-test assumes that the underlying process generates data that follows a normal distribution. This makes sense since we have to make these assumptions in order to generate a distribution of expected t-statistics if the null were true.</p>
<p>Using simulation we can see what happens to the t-stastic as our data depart from this normality assumption. First, let’s simulate measurements from two groups as samples from two normal distributions with different mean parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">group1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">500</span>, <span class="dt">m =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">0.5</span>)
group2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">500</span>, <span class="dt">m =</span> <span class="fl">0.1</span>, <span class="dt">sd =</span> <span class="fl">0.5</span>)</code></pre></div>
<p>Always a good idea to visualize these data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(group1), <span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(group2), <span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="dt">size =</span> <span class="fl">1.5</span>)</code></pre></div>
<p><img src="bookdown-stats60_files/figure-html/unnamed-chunk-27-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>What do you think? Are these groups differnt from each other? Tricky, right? Let’s do a t-test to see how likely this difference is compared to the null hypothesis of no difference between the two groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="dt">x =</span> group1, <span class="dt">y =</span> group2, <span class="dt">paired =</span> F)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  group1 and group2
## t = -2.1399, df = 997.18, p-value = 0.0326
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.129675133 -0.005613819
## sample estimates:
##   mean of x   mean of y 
## -0.01376446  0.05388002</code></pre>

</div>
</div>







<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Formally, degrees of freedom are the number of values in the final calculation of a statistic that are free to vary.<a href="t-test.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptives.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>


<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-t_test.Rmd",
"text": "Edit"
},
"download": ["bookdown-stats60.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
